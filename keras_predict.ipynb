{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgeKJ81-mGjN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"ayNClqmZuOOBeL6lFjA348UfsA0jpzazy8pjyXsQ\"\n",
        "API_IDS = {'wind': 'EBA.MISO-ALL.NG.WND.H',\n",
        "        'solar': 'EBA.MISO-ALL.NG.SUN.H',\n",
        "        'hydro': 'EBA.MISO-ALL.NG.WAT.H',\n",
        "        'coal': 'EBA.MISO-ALL.NG.COL.H',\n",
        "        'natural_gas': 'EBA.MISO-ALL.NG.NG.H',\n",
        "        'nuclear': 'EBA.MISO-ALL.NG.NUC.H',\n",
        "        'other': 'EBA.MISO-ALL.NG.OTH.H'}\n",
        "HEADERS = {'Content-Type': 'application/json'}\n",
        "USERNAME = input()\n",
        "PASSWORD = input()"
      ],
      "metadata": {
        "id": "Ah630kXmmPxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_historical_pi_data(name, start_time, end_time, interval):\n",
        "    base_url = 'https://itsnt2259.iowa.uiowa.edu/piwebapi/search/query?q=name:'\n",
        "    url = base_url + name\n",
        "    query = requests.get(url, auth=(USERNAME, PASSWORD), headers=HEADERS).json()\n",
        "    self_url = query['Items'][0]['Links']['Self']\n",
        "    point = requests.get(self_url, auth=(USERNAME, PASSWORD), headers=HEADERS).json()\n",
        "    data_url = point['Links']['InterpolatedData']\n",
        "    data_url = data_url + '/?startTime=-' + start_time + '&endTime=-' + end_time + '&interval=' + interval\n",
        "    data = requests.get(data_url, auth=(USERNAME, PASSWORD), headers=HEADERS).json()\n",
        "    return data\n",
        "\n",
        "def get_historical_df(names, startTime, endTime, interval):\n",
        "    df = pd.DataFrame()\n",
        "    for i, name in enumerate(names):\n",
        "        data = get_historical_pi_data(name, startTime, endTime, interval)\n",
        "        items = data['Items']\n",
        "        if i == 0:\n",
        "            times = [int(datetime.strptime(item['Timestamp'][:-2], '%Y-%m-%dT%H:%M:%S.%f').timestamp()//3600) for item in items]\n",
        "            df['Time'] = times\n",
        "        validateData = lambda x: min(x, 50) if (isinstance(x, (int, float)) and x >= 0) else 0\n",
        "        vals = [validateData(item['Value']) for item in items]\n",
        "        df[name] = pd.DataFrame(vals)\n",
        "    return df"
      ],
      "metadata": {
        "id": "MqTEdzNQmWom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTotalLoad(startTime=\"520w\", endTime=\"1d\", interval=\"1h\"):\n",
        "    names = ['PP_Electric_Purch', 'PP_Electric_Gen']\n",
        "    df = get_historical_df(names, startTime, endTime, interval)\n",
        "    df['Load'] = df['PP_Electric_Purch'] + df['PP_Electric_Gen']\n",
        "    return df\n",
        "data = getTotalLoad()\n",
        "print(data)"
      ],
      "metadata": {
        "id": "Vrk-4EzcmWs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert2matrix(data_arr, look_back):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data_arr)-look_back):\n",
        "        d=i+look_back  \n",
        "        X.append(data_arr[i:d,0])\n",
        "        Y.append(data_arr[d,0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "load_data = data[['Load']]\n",
        "load_data.head()\n"
      ],
      "metadata": {
        "id": "sc7vJIzLm5-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data set into testing dataset and train dataset\n",
        "train_size, val_size = int(load_data.shape[0]*0.95), int(load_data.shape[0]*0.01)\n",
        "train, val, test = \\\n",
        "    load_data.values[0:train_size, :], load_data.values[train_size:train_size+val_size, :], load_data.values[train_size+val_size:, :]\n",
        "\n",
        "# setup look_back window \n",
        "look_back = 24\n",
        "\n",
        "#convert dataset into right shape in order to input into the DNN\n",
        "trainX, trainY = convert2matrix(train, look_back)\n",
        "valX, valY = convert2matrix(val, look_back)\n",
        "testX, testY = convert2matrix(test, look_back)\n",
        "\n",
        "print(\"Training data:\", train.shape)\n",
        "print(\"Validation data:\", val.shape)\n",
        "print(\"Testing data:\", test.shape)\n"
      ],
      "metadata": {
        "id": "JOIVzJOxoq2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "def model_dnn(look_back):\n",
        "    model=Sequential()\n",
        "    model.add(Dense(units=32, input_dim=look_back, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n",
        "    return model\n",
        "\n",
        "def model_loss(history):\n",
        "    fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
        "    ax[0].plot(history.history['loss'], label='Train Loss')\n",
        "    ax[0].set_title('Training Loss')\n",
        "    ax[0].set_ylabel('loss')\n",
        "    ax[0].set_xlabel('epochs')\n",
        "    ax[0].legend(loc='upper right')\n",
        "\n",
        "    ax[1].plot(history.history['val_loss'], label='Val Loss')\n",
        "    ax[1].set_title('Validation Loss')\n",
        "    ax[1].set_ylabel('loss')\n",
        "    ax[1].set_xlabel('epochs')\n",
        "    ax[1].legend(loc='upper right')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KOTOO8FdKc_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model   = model_dnn(look_back)\n",
        "history = model.fit(trainX, trainY, epochs=100, batch_size=30, verbose=1, validation_data=(valX, valY), \\\n",
        "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)], shuffle=False)"
      ],
      "metadata": {
        "id": "KGVn7KwqSqlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = model.evaluate(trainX, trainY, verbose=0)\n",
        "print('Train Root Mean Squared Error(RMSE): %.2f; Train Mean Absolute Error(MAE) : %.2f ' % (np.sqrt(train_score[1]), train_score[2]))\n",
        "test_score = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Root Mean Squared Error(RMSE): %.2f; Test Mean Absolute Error(MAE) : %.2f ' % (np.sqrt(test_score[1]), test_score[2]))\n",
        "model_loss(history)"
      ],
      "metadata": {
        "id": "EBETRn6-aDHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict = model.predict(testX)"
      ],
      "metadata": {
        "id": "oHV316zObgi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_plot(testY, test_predict):\n",
        "    len_prediction=[x for x in range(len(testY))]\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.plot(len_prediction, testY, marker='.', label=\"actual\")\n",
        "    plt.plot(len_prediction, test_predict, 'r', label=\"prediction\")\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(left=0.07)\n",
        "    plt.ylabel('Load', size=15)\n",
        "    plt.xlabel('Time step', size=15)\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "prediction_plot(testY, test_predict)"
      ],
      "metadata": {
        "id": "4PxOUdrzSGZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"load_predictor\")"
      ],
      "metadata": {
        "id": "U3yBS5raT3Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model = keras.models.load_model(\"load_predictor\")"
      ],
      "metadata": {
        "id": "LAfXCT3kSGof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.testing.assert_allclose(\n",
        "    model.predict(testX), reconstructed_model.predict(testX)\n",
        ")"
      ],
      "metadata": {
        "id": "twyK9R1WeUZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}